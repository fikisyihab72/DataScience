{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PrQVcF-ldGWQ"
   },
   "source": [
    "<h1> Soal 1: Pemahaman Tentang Model Evaluasi</h1>\n",
    "\n",
    "Jawab pertanyaan di bawah ini dengan bahasa masing-masing?\n",
    "\n",
    "1. Apa perbedaan antara data latih, data validasi, dan data test?\n",
    "2. Bagaimana cara kita menilai performa suatu model?\n",
    "3. Apa itu Confusion Matrix? Jelaskan secara lengkap!\n",
    "4. Apa itu Classification Report dari sklearn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sr6D5UIhgpwO"
   },
   "source": [
    "Jawab:\n",
    "1. - Data Latih adalah data yang digunakan untuk training model\n",
    "   - Data Validation digunakan untuk proses validasi model dan mencegah overfitting.\n",
    "   - Data Testing, digunakan untuk testing model, sebagai simulasi penggunaan model pada dunia nyata. Data testing tidak boleh pernah dilihat oleh model sebelumnya.\n",
    "2. Performa model yang bagus adalah model yang dapat memprediksi suatu data yang belum pernah diliat sebelumnya dengan tepat. \n",
    "3. Confusion matrix juga sering disebut error matrix. Pada dasarnya confusion matrix memberikan informasi perbandingan hasil klasifikasi yang dilakukan oleh sistem (model) dengan hasil klasifikasi sebenarnya. Confusion matrix berbentuk tabel matriks yang menggambarkan kinerja model klasifikasi pada serangkaian data uji yang nilai sebenarnya diketahui. \n",
    "4. Classification Report adalah fungsi dari sklearn yang berguna untuk memvisualisasikan hasil Confussion Matrix berupa Precission, Recall, F1-Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uY-s7-KDgrkV"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fv2TVsgAdGWY"
   },
   "source": [
    "<h1>Soal 2: Aplikasi Model Evaluasi</h1>\n",
    "\n",
    "Kali ini kita akan menggunakan data untuk memprediksi kelangsungan hidup pasien yang telah mengalami operasi payudara. Dengan informasi yang dimiliki terkait pasien, kita akan membuat model untuk memprediksi apakah pasien akan bertahan hidup dalam waktu lebih dari 5 tahun atau tidak.\n",
    "\n",
    "Lebih Lengkapnya kalian bisa membaca informasi tentang dataset di link berikut: https://raw.githubusercontent.com/jbrownlee/Datasets/master/haberman.names\n",
    "\n",
    "Buat model Klasifikasi (Model/Algoritma Bebas) untuk memprediksi status pasien dengan ketentuan sebagai berikut:\n",
    "\n",
    "1. Bagi kedua data ini menjadi data training dan data test dengan test_size=0.25.\n",
    "3. Pelajar tentang metrics roc_auc_score kemudian buatlah model dan evaluasi dengan menggunakan teknik cross-validation dengan scoring 'roc_auc'. Baca https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html untuk menggunakan metric roc_auc saat cross-validation.\n",
    "3. Berapa score rata2 dari model dengan teknik cross-validation tersebut?\n",
    "4. Prediksi data test dengan model yang telah kalian buat!\n",
    "5. Bagaimana hasil confusion matrix dari hasil prediksi tersebut?\n",
    "6. Bagaimana classification report dari hasil prediksi tersebut?\n",
    "5. Seberapa baik model anda dalam memprediksi seorang pasien mempunyai status positive?\n",
    "6. Seberapa baik model anda dalam memprediksi seorang pasien mempunyai status negatif?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g4UqaWyPdGWj"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/haberman.csv'\n",
    "list_cols = ['Age', \"Patient's Years\", \"N_positive_ax\", \"survival_status\"]\n",
    "df = pd.read_csv(url, names=list_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YrbPNGtHdGXV"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Patient's Years</th>\n",
       "      <th>N_positive_ax</th>\n",
       "      <th>survival_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>65</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Patient's Years  N_positive_ax  survival_status\n",
       "0   30               64              1                1\n",
       "1   30               62              3                1\n",
       "2   30               65              0                1\n",
       "3   31               59              2                1\n",
       "4   31               65              4                1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-dxYNPg7dGX4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    225\n",
       "2     81\n",
       "Name: survival_status, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['survival_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Membagi data feature dan data target\n",
    "x = df.drop('survival_status', axis=1)\n",
    "y = df['survival_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8W2amvZgdGYX"
   },
   "outputs": [],
   "source": [
    "# Code here\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "x_train, x_test, y_train, y_test=train_test_split(x, y, test_size=0.25, random_state=50, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_knn = KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_knn.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_result = cross_val_score(model_knn, x, y, cv=5,  scoring='roc_auc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.70261438, 0.55277778, 0.63888889, 0.67916667, 0.60694444])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6360784313725489\n"
     ]
    }
   ],
   "source": [
    "#Rata rata hasil Cross Validation\n",
    "print(cv_result.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 2 1 1 1 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 2 1 1\n",
      " 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 2 2\n",
      " 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#Prediksi data test dengan model yang telah dibuat\n",
    "y_predict = model_knn.predict(x_test)\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[49,  8],\n",
       "       [12,  8]], dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hasil confusion matrix\n",
    "confusion_matrix(y_test, y_predict, labels=[1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.86      0.83        57\n",
      "           2       0.50      0.40      0.44        20\n",
      "\n",
      "    accuracy                           0.74        77\n",
      "   macro avg       0.65      0.63      0.64        77\n",
      "weighted avg       0.72      0.74      0.73        77\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#hasil clasification report\n",
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Posiif\n",
      "Precision :  0.8032786885245902\n",
      "Precision :  0.8596491228070176\n",
      "F1-Score  : 0.8305084745762712\n",
      "\n",
      "Data Negatif\n",
      "Precision :  0.5\n",
      "Precision :  0.4\n",
      "F1-Score  : 0.4444444444444445\n"
     ]
    }
   ],
   "source": [
    "TP = 49\n",
    "FN = 8\n",
    "FP = 12\n",
    "TN = 8\n",
    "\n",
    "print('Data Posiif')\n",
    "precision = TP/(TP+FP)\n",
    "print(f'Precision : ',precision)\n",
    "recall = TP/(TP+FN)\n",
    "print(f'Precision : ',recall)\n",
    "f1score = 2*precision*recall/(precision+recall)\n",
    "print(f'F1-Score  :',f1score)\n",
    "print('')\n",
    "print('Data Negatif')\n",
    "precisionN = TN/(TN+FN)\n",
    "print(f'Precision : ',precisionN)\n",
    "recallN = TN/(TN+FP)\n",
    "print(f'Precision : ',recallN)\n",
    "f1scoreN = 2*precisionN*recallN/(precisionN+recallN)\n",
    "print(f'F1-Score  :',f1scoreN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I6v_dgoN-7wL"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "teekoyIw--g2"
   },
   "source": [
    "<h1> Soal 3: Pemahaman Tentang Model Selection</h1>\n",
    "\n",
    "Jelaskan dengan bahasa sendiri!\n",
    "\n",
    "1. Apa itu Bias dan Variance?\n",
    "2. Apa itu Overfitting dan Underfitting?\n",
    "3. Apa yang bisa kita lakukan untuk mengatur kompleksitas dari model?\n",
    "4. Bagaimana model yang baik?\n",
    "5. Kapan kita menggunakan GridSearchcv dan kapan menggunakan RandomizedSearchCV?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4a1l4RNf_FcU"
   },
   "source": [
    "Jawab:\n",
    "1. - Bias adalah error yang diseabkan karena pengggunaan model yang terlalu simple sehingga tidak dapat memprediksi dengan baik\n",
    "   - Variance adalah error yang disebabkan dikarenakan model yang terlalu fit ke data latih dan mempelajari terlalu dalam sehingga jika terdapat data testing akan sulit untuk memprediksi dengan benar\n",
    "2. - Overfitting adalah suatu keadaan dimana data yang digunakan untuk pelatihan itu adalah yang \"terbaik\". Sehingga apabila dilakukan tes dengan menggunakan data yang berbeda dapat mengurangi akurasi \n",
    "   - Underfitting adalah keadaan dimana model pelatihan data yang dibuat tidak mewakilkan keseluruhan data yang akan digunakan nantinya.\n",
    "3. Untuk melalukan kompleksitas model harus mempertimbangkan bentuk data terlebih dahulu yang mana data tersebut data simple atau komplek, data tersebut balance atau imbalance, dan juga memperhatikan kelengkapan data dan noise yang ada\n",
    "4. Model yang baik adalah model yang memiliki titik tengah antara Bias dan Variance sehingga model tidak terlalu simple dan tidak terlalu fit ke data training\n",
    "5. - GridSeachCV digunakan saat data yang diambil tidak terlalu banyak noise dan simple dikarenakan semua data akan di search kombinasinya sehingga memakan waktu dan performa\n",
    "   - RandomizedSearchCV bekerja paling baik untuk data dimensi yang lebih rendah karena waktu yang dibutuhkan untuk menemukan set yang tepat lebih sedikit dengan jumlah iterasi yang lebih sedikit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Svj_cgxF_IZv"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hkh-PeRL_LZp"
   },
   "source": [
    "<h1> Soal 4: Aplikasi Model Selection</h1>\n",
    "\n",
    "1. Bagi kedua data berikut ini menjadi data training dan data test dengan test_size=0.25.\n",
    "2. Gunakan algoritma KNN sebagai model classifier.\n",
    "3. Gunakan fungsi GridSearchCV untuk hyperparameter tuning dan model selection.\n",
    "4. jumlah fold bebas!, gunakan scoring 'roc_auc'\n",
    "5. Definisikan kombinasi hyperparameter untuk model selection dengan GridSearchCV. kombinasi Hyperparameter bebas, baca lagi dokumentasi KNN di link berikut https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html untuk memahami lagi jenis2 hyperparameter di algorithma KNN.\n",
    "6. Latih model terhadap data training.\n",
    "7. Apa hyperparameter terbaik untuk kombinasi hyperparameter kalian?\n",
    "8. Berapa score validasi terbaik dari model tersebut?\n",
    "9. Prediksi probabilitasi output dari model yang telah di buat terhadap data test. note : gunakan method .predict_proba() untuk menghasilkan output probabilitas\n",
    "10. Perhatikan bahwa hasil prediksi ada 2, dimana masing2 adalah nilai probabilitas untuk setiap class label. Ambil nilai probabilitas pasien phositive meninggal dalam waktu kurang dari 5 tahun. note : gunakan bantuan attirubte .classes_ untuk mengetahui urutan label dari hasil prediksi probabilitas.\n",
    "11. Berapa nilai score roc_auc untuk data test?\n",
    "12. Apakah model anda termasuk baik, overtting, atau underfitting?\n",
    "13. Ulangi tahap di atas namun kali ini menggunakan algoritma DecisionTreeClassifier dan kalian bisa menggunakan RandomizedSearchCV apabila process training lama. pelajari algoritma DecisionTreeClassifier di linkberikut: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html?highlight=decisiontreeclassifier#sklearn.tree.DecisionTreeClassifier\n",
    "14. Bandingkan scorenya dengan Algoritma KNN, mana yang lebih baik?\n",
    "\n",
    "Note : Data Science adalah experiment, sangat di dimungkinkan memerlukan beberapa kali percobaan untuk mendapatkan hasil yang terbaik! Happy Coding :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l_zK8Mqb-9Z6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/haberman.csv'\n",
    "list_cols = ['Age', \"Patient's Years\", \"N_positive_ax\", \"survival_status\"]\n",
    "df = pd.read_csv(url, names=list_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qb-AD43R_V_d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Patient's Years</th>\n",
       "      <th>N_positive_ax</th>\n",
       "      <th>survival_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>65</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Patient's Years  N_positive_ax  survival_status\n",
       "0   30               64              1                1\n",
       "1   30               62              3                1\n",
       "2   30               65              0                1\n",
       "3   31               59              2                1\n",
       "4   31               65              4                1"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('survival_status', axis=1)\n",
    "y = df['survival_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "znc1dEGO_XU2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(n_neighbors=3),\n",
       "             param_grid={'n_neighbors': array([ 3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
       "       20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36,\n",
       "       37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
       "       54, 55, 56, 57, 58, 59]),\n",
       "                         'weights': ['distance', 'uniform']},\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code here\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "x_train, x_test, y_train, y_test=train_test_split(x, y, test_size=0.25, random_state=50, stratify=y)\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "param_grid = {'n_neighbors':np.arange(3, 60), 'weights':['distance', 'uniform']}\n",
    "gscv = GridSearchCV(model, param_grid=param_grid, scoring='roc_auc', cv=5)\n",
    "gscv.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter terbaik :  {'n_neighbors': 22, 'weights': 'uniform'}\n",
      "Score validasi terbaik :  0.7021476072946661\n"
     ]
    }
   ],
   "source": [
    "print(f'Hyperparameter terbaik : ',gscv.best_params_)\n",
    "print(f'Score validasi terbaik : ',gscv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.72727273 0.27272727]\n",
      " [0.77272727 0.22727273]\n",
      " [0.5        0.5       ]\n",
      " [0.77272727 0.22727273]\n",
      " [0.40909091 0.59090909]\n",
      " [0.45454545 0.54545455]\n",
      " [0.81818182 0.18181818]\n",
      " [0.90909091 0.09090909]\n",
      " [0.95454545 0.04545455]\n",
      " [0.86363636 0.13636364]\n",
      " [0.40909091 0.59090909]\n",
      " [0.81818182 0.18181818]\n",
      " [0.59090909 0.40909091]\n",
      " [0.40909091 0.59090909]\n",
      " [0.81818182 0.18181818]\n",
      " [0.90909091 0.09090909]\n",
      " [0.95454545 0.04545455]\n",
      " [0.95454545 0.04545455]\n",
      " [0.81818182 0.18181818]\n",
      " [0.63636364 0.36363636]\n",
      " [0.86363636 0.13636364]\n",
      " [0.81818182 0.18181818]\n",
      " [0.72727273 0.27272727]\n",
      " [0.86363636 0.13636364]\n",
      " [0.77272727 0.22727273]\n",
      " [0.72727273 0.27272727]\n",
      " [0.31818182 0.68181818]\n",
      " [0.90909091 0.09090909]\n",
      " [0.40909091 0.59090909]\n",
      " [0.90909091 0.09090909]\n",
      " [0.86363636 0.13636364]\n",
      " [0.77272727 0.22727273]\n",
      " [0.77272727 0.22727273]\n",
      " [0.86363636 0.13636364]\n",
      " [0.81818182 0.18181818]\n",
      " [0.86363636 0.13636364]\n",
      " [0.63636364 0.36363636]\n",
      " [0.5        0.5       ]\n",
      " [0.90909091 0.09090909]\n",
      " [0.81818182 0.18181818]\n",
      " [0.86363636 0.13636364]\n",
      " [0.90909091 0.09090909]\n",
      " [0.81818182 0.18181818]\n",
      " [0.68181818 0.31818182]\n",
      " [0.72727273 0.27272727]\n",
      " [0.90909091 0.09090909]\n",
      " [0.5        0.5       ]\n",
      " [0.81818182 0.18181818]\n",
      " [0.81818182 0.18181818]\n",
      " [0.81818182 0.18181818]\n",
      " [0.86363636 0.13636364]\n",
      " [0.86363636 0.13636364]\n",
      " [0.45454545 0.54545455]\n",
      " [0.63636364 0.36363636]\n",
      " [0.77272727 0.22727273]\n",
      " [0.86363636 0.13636364]\n",
      " [0.95454545 0.04545455]\n",
      " [0.81818182 0.18181818]\n",
      " [0.90909091 0.09090909]\n",
      " [0.81818182 0.18181818]\n",
      " [0.40909091 0.59090909]\n",
      " [0.81818182 0.18181818]\n",
      " [0.81818182 0.18181818]\n",
      " [0.59090909 0.40909091]\n",
      " [0.90909091 0.09090909]\n",
      " [0.90909091 0.09090909]\n",
      " [0.90909091 0.09090909]\n",
      " [0.72727273 0.27272727]\n",
      " [0.68181818 0.31818182]\n",
      " [0.77272727 0.22727273]\n",
      " [0.86363636 0.13636364]\n",
      " [0.81818182 0.18181818]\n",
      " [0.72727273 0.27272727]\n",
      " [0.81818182 0.18181818]\n",
      " [0.81818182 0.18181818]\n",
      " [0.86363636 0.13636364]\n",
      " [0.77272727 0.22727273]]\n"
     ]
    }
   ],
   "source": [
    "hasil_proba = gscv.predict_proba(x_test)\n",
    "print(hasil_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2], dtype=int64)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.27272727 0.22727273 0.5        0.22727273 0.59090909 0.54545455\n",
      " 0.18181818 0.09090909 0.04545455 0.13636364 0.59090909 0.18181818\n",
      " 0.40909091 0.59090909 0.18181818 0.09090909 0.04545455 0.04545455\n",
      " 0.18181818 0.36363636 0.13636364 0.18181818 0.27272727 0.13636364\n",
      " 0.22727273 0.27272727 0.68181818 0.09090909 0.59090909 0.09090909\n",
      " 0.13636364 0.22727273 0.22727273 0.13636364 0.18181818 0.13636364\n",
      " 0.36363636 0.5        0.09090909 0.18181818 0.13636364 0.09090909\n",
      " 0.18181818 0.31818182 0.27272727 0.09090909 0.5        0.18181818\n",
      " 0.18181818 0.18181818 0.13636364 0.13636364 0.54545455 0.36363636\n",
      " 0.22727273 0.13636364 0.04545455 0.18181818 0.09090909 0.18181818\n",
      " 0.59090909 0.18181818 0.18181818 0.40909091 0.09090909 0.09090909\n",
      " 0.09090909 0.27272727 0.31818182 0.22727273 0.13636364 0.18181818\n",
      " 0.27272727 0.18181818 0.18181818 0.13636364 0.22727273]\n"
     ]
    }
   ],
   "source": [
    "positif_die_5_year = hasil_proba[:,1]\n",
    "print(positif_die_5_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score ROC_AUC (KNN) :  0.6298245614035087\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "y_predik = model.predict(x_test)\n",
    "\n",
    "score_roc_auc = roc_auc_score(y_test, y_predik)\n",
    "print('Score ROC_AUC (KNN) : ', score_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
       "                   param_distributions={'max_leaf_nodes': [2, 3, 4, 5, 6, 7, 8,\n",
       "                                                           9, 10, 11, 12, 13,\n",
       "                                                           14, 15, 16, 17, 18,\n",
       "                                                           19, 20, 21, 22, 23,\n",
       "                                                           24, 25, 26, 27, 28,\n",
       "                                                           29, 30, 31, ...],\n",
       "                                        'min_samples_split': [2, 3, 4]},\n",
       "                   scoring='accuracy')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "dtc = DecisionTreeClassifier()\n",
    "params = {'max_leaf_nodes': list(range(2, 100)), 'min_samples_split': [2, 3, 4]}\n",
    "rscv = RandomizedSearchCV(dtc, params, scoring='accuracy', cv=5)\n",
    "rscv.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score ROC_AUC (Decision Tree Clasiffier) :  0.6197368421052631\n"
     ]
    }
   ],
   "source": [
    "dtc.fit(x_train, y_train)\n",
    "y_predik = dtc.predict(x_test)\n",
    "\n",
    "score_roc_auc = roc_auc_score(y_test, y_predik)\n",
    "print('Score ROC_AUC (Decision Tree Clasiffier) : ', score_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Tugas Hari 3 Pekan 4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
